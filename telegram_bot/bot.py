import os
import logging
import requests
import time
import json
import io
import pandas as pd
from aiogram import Bot, Dispatcher, types
from aiogram.types import ParseMode, InputFile
from aiogram.utils import executor
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.dispatcher import FSMContext
from aiogram.contrib.fsm_storage.memory import MemoryStorage

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
)
logger = logging.getLogger(__name__)

# Get token from environment variable
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_TOKEN not found in environment variables")

# URL for the AI detector service API
FASTAPI_URL = "http://fastapi_app:8000/analyze/document"
HEALTH_CHECK_URL = "http://fastapi_app:8000/health"
TEXT_ANALYZE_URL = "http://fastapi_app:8000/analyze/text"


# Function to check API availability
def is_api_ready():
    try:
        response = requests.get(HEALTH_CHECK_URL, timeout=5)
        data = response.json()
        if data["status"] == "ok":
            return True
        logger.info(f"API is not ready yet: {data}")
        return False
    except Exception as e:
        logger.warning(f"Error checking API readiness: {e}")
        return False


# Initialize bot and dispatcher
bot = Bot(token=TELEGRAM_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(bot, storage=storage)


# Define states for FSM
class DetectorStates(StatesGroup):
    waiting_for_file = State()
    waiting_for_text = State()


# Handler for /start command
@dp.message_handler(commands=['start'], state='*')
async def send_welcome(message: types.Message):
    await message.reply(
        "🤖 Welcome to the AI Text Detector Bot!\n\n"
        "I can analyze text to determine if it was generated by AI.\n\n"
        "You can send me:\n"
        "- A Word document (.docx) to analyze\n"
        "- Or use /text to analyze text directly\n\n"
        "I'll provide you with a detailed analysis showing the AI generation probability for each paragraph."
    )
    await DetectorStates.waiting_for_file.set()


# Handler for /help command
@dp.message_handler(commands=['help'], state='*')
async def send_help(message: types.Message):
    await message.reply(
        "🔍 How to use the AI Text Detector Bot:\n\n"
        "1. Send a Word document (.docx) to analyze\n"
        "2. Or use /text command to enter text directly\n"
        "3. Wait while I analyze the content\n"
        "4. Receive a detailed report showing AI-generated probability for each paragraph\n\n"
        "Commands:\n"
        "• /start - Start the bot and reset state\n"
        "• /text - Analyze custom text\n"
        "• /help - Show this help message\n"
        "• /status - Check if the detection service is operational"
    )


# Handler for /text command - to analyze custom text
@dp.message_handler(commands=['text'], state='*')
async def request_text_input(message: types.Message):
    await message.reply(
        "Please send me the text you want to analyze for AI-generated content.\n\n"
        "For best results, send multiple paragraphs of text."
    )
    await DetectorStates.waiting_for_text.set()


# Handler for /status command - to check API status
@dp.message_handler(commands=['status'], state='*')
async def check_api_status(message: types.Message):
    await message.reply("🔄 Checking AI detection service status...")
    if is_api_ready():
        await message.reply("✅ AI detection service is working normally and ready to use!")
    else:
        await message.reply("⚠️ AI detection service is currently unavailable or loading. Try again later.")


# Handler for document files
@dp.message_handler(state=DetectorStates.waiting_for_file, content_types=types.ContentTypes.DOCUMENT)
async def process_document(message: types.Message, state: FSMContext):
    # Check API readiness before sending request
    if not is_api_ready():
        await message.reply(
            "⚠️ AI detection service is currently loading or unavailable. "
            "Please try again in a few minutes."
        )
        return

    document = message.document

    # Check if it's a Word document
    if not document.file_name.lower().endswith('.docx'):
        await message.reply(
            "⚠️ Please send a Microsoft Word document (.docx).\n"
            "Other file formats are not supported at this time."
        )
        return

    # Send "typing" status
    await bot.send_chat_action(message.chat.id, 'typing')

    # Send message about processing start
    processing_msg = await message.reply(
        "📄 Processing your document... This may take a minute depending on document size."
    )

    try:
        # Download the file
        file_info = await bot.get_file(document.file_id)
        downloaded_file = await bot.download_file(file_info.file_path)

        # Prepare the file for multipart upload
        files = {'file': (
            document.file_name, downloaded_file,
            'application/vnd.openxmlformats-officedocument.wordprocessingml.document')}

        # Make request to the API
        response = requests.post(FASTAPI_URL, files=files, timeout=300)

        if response.status_code == 200:
            data = response.json()
            results = data.get('results', [])

            if not results:
                await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
                await message.reply(
                    "⚠️ No analyzable text found in the document. "
                    "Please check if your document contains text content."
                )
                return

            # Create a dataframe for better formatting
            df = pd.DataFrame(results)

            # Rename column from paragraph to text for backwards compatibility
            df.rename(columns={'paragraph': 'text'}, inplace=True)

            # Generate CSV file
            output = io.StringIO()
            df.to_csv(output, index=False)
            output.seek(0)

            # Create text-based summary
            summary_text = "🔍 **AI Text Detection Results**\n\n"

            # Count high-probability paragraphs (>0.8)
            high_prob_count = sum(1 for r in results if r['probability'] > 0.8)
            medium_prob_count = sum(1 for r in results if 0.5 < r['probability'] <= 0.8)
            low_prob_count = sum(1 for r in results if r['probability'] <= 0.5)
            total_paragraphs = len(results)

            summary_text += f"**Document Analysis Summary:**\n"
            summary_text += f"- Total paragraphs analyzed: {total_paragraphs}\n"
            summary_text += f"- High probability AI-generated (>80%): {high_prob_count} paragraphs ({round(high_prob_count / total_paragraphs * 100, 1)}%)\n"
            summary_text += f"- Medium probability (50-80%): {medium_prob_count} paragraphs ({round(medium_prob_count / total_paragraphs * 100, 1)}%)\n"
            summary_text += f"- Low probability (<50%): {low_prob_count} paragraphs ({round(low_prob_count / total_paragraphs * 100, 1)}%)\n\n"

            summary_text += "Detailed results are available in the attached CSV file."

            # Send the summary text
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(summary_text, parse_mode=ParseMode.MARKDOWN)

            # Send CSV file with detailed results
            csv_file = InputFile(io.BytesIO(output.getvalue().encode()),
                                 filename=f"{document.file_name.split('.')[0]}_ai_analysis.csv")
            await message.reply_document(csv_file, caption="Detailed AI detection results for each paragraph")

        elif response.status_code == 503:
            # Special handling for the case when the model is still loading
            logger.warning("API responded with 503 - service is still loading")
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(
                "⏳ The AI detection model is still loading. Please wait a few minutes and try again."
            )
        else:
            error_text = response.text
            logger.error(f"API Error: {response.status_code} - {error_text}")
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(
                "😞 An error occurred while analyzing your document. Please try again later."
            )
    except requests.exceptions.Timeout:
        logger.error("Timeout when requesting API")
        await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
        await message.reply(
            "⏱️ The request is taking too long. Your document might be too large. "
            "Please try with a smaller document."
        )
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
        await message.reply(f"😞 An unexpected error occurred: {str(e)}")


# Handler for text analysis
@dp.message_handler(state=DetectorStates.waiting_for_text, content_types=types.ContentTypes.TEXT)
async def process_text(message: types.Message, state: FSMContext):
    user_text = message.text

    # Check if text is too short
    if len(user_text.strip()) < 50:
        await message.reply(
            "⚠️ Please provide a longer text for accurate analysis (at least 50 characters)."
        )
        return

    # Check API readiness before sending request
    if not is_api_ready():
        await message.reply(
            "⚠️ AI detection service is currently loading or unavailable. "
            "Please try again in a few minutes."
        )
        return

    # Send "typing" status
    await bot.send_chat_action(message.chat.id, 'typing')

    # Send message about processing start
    processing_msg = await message.reply("🔍 Analyzing your text... This will take a moment.")

    try:
        # Make request to the API
        response = requests.post(
            TEXT_ANALYZE_URL,
            json={"text": user_text},
            timeout=60
        )

        if response.status_code == 200:
            results = response.json()

            if not results:
                await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
                await message.reply(
                    "⚠️ No analyzable paragraphs found in your text. "
                    "Please check your input and try again."
                )
                return

            # Create a dataframe
            df = pd.DataFrame(results)

            # Rename column from paragraph to text for backwards compatibility
            df.rename(columns={'paragraph': 'text'}, inplace=True)

            # Generate CSV file
            output = io.StringIO()
            df.to_csv(output, index=False)
            output.seek(0)

            # Create text-based summary
            summary_text = "🔍 **AI Text Detection Results**\n\n"

            # Count high-probability paragraphs (>0.8)
            high_prob_count = sum(1 for r in results if r['probability'] > 0.8)
            medium_prob_count = sum(1 for r in results if 0.5 < r['probability'] <= 0.8)
            low_prob_count = sum(1 for r in results if r['probability'] <= 0.5)
            total_paragraphs = len(results)

            summary_text += f"**Text Analysis Summary:**\n"
            summary_text += f"- Total paragraphs analyzed: {total_paragraphs}\n"
            summary_text += f"- High probability AI-generated (>80%): {high_prob_count} paragraphs ({round(high_prob_count / total_paragraphs * 100, 1)}%)\n"
            summary_text += f"- Medium probability (50-80%): {medium_prob_count} paragraphs ({round(medium_prob_count / total_paragraphs * 100, 1)}%)\n"
            summary_text += f"- Low probability (<50%): {low_prob_count} paragraphs ({round(low_prob_count / total_paragraphs * 100, 1)}%)\n\n"

            # Add sample of analyzed paragraphs with high probability
            if high_prob_count > 0:
                summary_text += "**Sample High-Probability Paragraphs:**\n"
                high_prob_samples = [r for r in results if r['probability'] > 0.8][:2]  # Take up to 2 samples
                for i, sample in enumerate(high_prob_samples, 1):
                    summary_text += f"{i}. \"{sample['paragraph'][:100]}...\" - {round(sample['probability'] * 100, 1)}%\n"
                summary_text += "\n"

            summary_text += "Detailed results are available in the attached CSV file."

            # Send the summary text
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(summary_text, parse_mode=ParseMode.MARKDOWN)

            # Send CSV file with detailed results
            csv_file = InputFile(io.BytesIO(output.getvalue().encode()), filename="text_ai_analysis.csv")
            await message.reply_document(csv_file, caption="Detailed AI detection results for each paragraph")

            # Reset state to waiting for file
            await DetectorStates.waiting_for_file.set()

        elif response.status_code == 503:
            logger.warning("API responded with 503 - service is still loading")
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(
                "⏳ The AI detection model is still loading. Please wait a few minutes and try again."
            )
        else:
            error_text = response.text
            logger.error(f"API Error: {response.status_code} - {error_text}")
            await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
            await message.reply(
                "😞 An error occurred while analyzing your text. Please try again later."
            )
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        await bot.delete_message(chat_id=processing_msg.chat.id, message_id=processing_msg.message_id)
        await message.reply(f"😞 An unexpected error occurred: {str(e)}")


# Handler for all other messages
@dp.message_handler(content_types=types.ContentTypes.ANY, state='*')
async def unknown_message(message: types.Message):
    await message.reply(
        "I can analyze Word documents (.docx) or text input.\n"
        "Please upload a document or use /text to analyze text directly.\n"
        "Use /help to learn more about how to use this bot."
    )


# Start the bot with waiting for API readiness
if __name__ == '__main__':
    logger.info("Starting Telegram bot...")
    # Wait until API is ready
    retry_count = 0
    max_retries = 30  # Maximum 5 minutes of waiting (30 * 10 seconds)
    retry_interval = 10  # 10 seconds between attempts
    logger.info("Checking API availability before starting the bot...")
    while not is_api_ready() and retry_count < max_retries:
        logger.info(f"Waiting for FastAPI service to be ready... Attempt {retry_count + 1}/{max_retries}")
        time.sleep(retry_interval)
        retry_count += 1
    if retry_count >= max_retries:
        logger.warning(
            "Could not wait for FastAPI service to be ready after several attempts. Starting the bot anyway.")
    else:
        logger.info("✅ FastAPI service is ready!")
    # Start the bot
    executor.start_polling(dp, skip_updates=True)